---
title: "432 Class 08"
author: Thomas E. Love, Ph.D.
date: "2024-02-08"
format:
  revealjs: 
    theme: default
    embed-resources: true
    self-contained: true
    slide-number: true
    footnotes-hover: true
    preview-links: auto
    date-format: iso
    logo: 432-2024-pic.png
    footer: "432 Class 08 | 2024-02-08 | <https://thomaselove.github.io/432-2024/>"
---

## Today's Agenda

-   The Bechdel-Wallace Test and the Favorite Movies Data
-   Three Logistic Regressions with `glm()` & `lrm()`
    -   Using tidy, glance and augment from `broom`
    -   Making Predictions with our models
    -   Interpreting exponentiated coefficients as odds ratios
    -   Likelihood Ratio and other ANOVA Tests
    -   ROC curve and the Area under the Curve
    -   Validating Model Summaries

## Today's R Setup

```{r}
#| echo: true
#| message: false
knitr::opts_chunk$set(comment = NA)

library(readxl) # import from Excel Sheet
library(skimr) # can help with exploration/cleaning
library(broom)
library(janitor)
library(gt)
library(naniar)
library(pROC)  # helps us plot ROC curves
library(rms)   # also loads Hmisc
library(tidyverse)

theme_set(theme_bw()) 
```

# "Favorite Movies" Data

## Ingest Data from an Excel Sheet

```{r}
#| echo: true

mov23_full <- read_xlsx("c08/data/movies_2023-10-24.xlsx")

dim(mov23_full)
```

### Select Today's Nine Variables

```{r}
#| echo: true
mov23 <- mov23_full |>
  select(film_id, bw_rating, year, mpa, metascore, 
         gross_world, comedy, drama, film) |>
  type.convert(as.is = FALSE) |>  # makes all character variables factors
  mutate(film_id = as.character(film_id),
         film = as.character(film))

dim(mov23)
```

## The Bechdel Test

> The Bechdel Test, or Bechdel-Wallace Test was popularized by Alison Bechdel's comic, in a 1985 strip called [The Rule](https://dykestowatchoutfor.com/the-rule/).

-   from <https://bechdeltest.com/>

The Bechdel-Wallace Test is a simple way to gauge the active presence of female characters in Hollywood films and just how well rounded and complete those roles are[^1].

[^1]: See <https://feministfrequency.com/video/the-bechdel-test-for-women-in-movies/>

## Passing the Bechdel-Wallace Test

To pass the test, a movie must have all three of the following.

-   at least two (named) women
-   who talk to each other
-   about something besides a man

```{r}
#| echo: true
mov23 <- mov23 |>
  mutate(bechdel = factor(ifelse(bw_rating == 3, "Pass", "Fail")))
mov23 |> count(bechdel, bw_rating) 
```

## Some Data Cleanup

1.  Drop the films missing the `bechdel` information.
2.  Create an `age` variable and use it instead of `year`, and
3.  Rescale world-wide gross by dividing by \$1,000,000.

```{r}
#| echo: true
mov23 <- mov23 |>
  filter(complete.cases(bechdel)) |>
  mutate(age = 2024-year,
         gross = gross_world/1000000)

mov23 |> tabyl(bechdel) |> adorn_pct_formatting()
```

## More Data Cleanup

How about the MPA ratings?

```{r}
#| echo: true
summary(mov23$mpa)
```

Let's collapse to the two largest categories, plus "Other"

```{r}
#| echo: true

mov23 <- mov23 |> mutate(mpa3 = fct_lump_n(mpa, n = 2))
mov23 |> tabyl(mpa3) |> adorn_pct_formatting() |> 
  gt() |> tab_options(table.font.size = 24)
```

## Any Missing Data?

```{r}
#| echo: true

## select the variables we're actually going to use

mov23a <- mov23 |>
  select(film_id, film, bechdel, age, gross, metascore, mpa3, comedy, drama)

miss_var_summary(mov23a) 
```

## Which movies are missing data?

```{r}
#| echo: true
mov23a |> filter(!complete.cases(metascore, gross)) |>
  select(film_id, metascore, gross, film)
```

## Today, we use complete cases

For today, let's just drop the films with missing data.

```{r}
#| echo: true
mov23a <- mov23a |> drop_na()

mov23a
```

## Codebook, part 1

| Variable  | Description                            |
|:---------:|:---------------------------------------|
| `film_id` | identifying code (M-001 through M-201) |
|  `film`   | title of film                          |
| `bechdel` | Bechdel Test Result (Pass or Fail)     |
|   `age`   | 2024 - Year of release (1942-2023)     |
|  `gross`  | Worldwide gross income in \$millions   |

Data Sources: <https://www.imdb.com/> and <https://bechdeltest.com>

## Codebook, part 2

|  Variable   | Description                                                                 |
|:-------------:|:--------------------------------------------------------|
| `metascore` | Metacritic score (from critics: 0-100 scale)                                |
|   `mpa3`    | MPA rating (now PG-13, R, Other)                                            |
|  `comedy`   | Is Comedy one of the movie's three genres listed at IMDB? (1 = Yes, 0 = No) |
|   `drama`   | Is Drama one of the movie's three genres listed at IMDB? (1 = Yes, 0 = No)  |

Data Sources: <https://www.imdb.com/> and <https://bechdeltest.com>

## Skim the `mov23a` data? {.smaller}

```{r}
#| echo: true
skim_output <- skim(mov23a)
summary(skim_output)
```

## Character Summary

```{r}
#| echo: true
skimr::yank(skim_output, "character") |> 
  gt() |> tab_options(table.font.size = 24)
```

### Factor Summary

```{r}
#| echo: true
yank(skim_output, "factor") |> 
  gt() |> tab_options(table.font.size = 24)
```

## Numeric Summary {.smaller}

```{r}
#| echo: true
skimr::yank(skim_output, "numeric")
```

## Splitting the sample?

We have `r nrow(mov23a)` films in our `mov23a` tibble.

-   It turns out that a logistic regression model needs about 96 observations just to fit a reasonable intercept term.
-   Each additional coefficient we fit requires another 10-20 observations just so that we *might* validate well.

Here, we want to explore six predictors (`age`, `mpa3`, `metascore`, `gross`, `comedy` and `drama`.)

-   Does it make sense to split our data into separate training and testing samples?

# Model 1. Using `age` to predict Pr(`bechdel` = Pass)

## The Logistic Regression Model {.smaller}

$$
logit(event) = log\left( \frac{Pr(event)}{1 - Pr(event)} \right) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_k X_k
$$

$$
odds(event) = \frac{Pr(event)}{1 - Pr(event)}
$$

$$
Pr(event) = \frac{odds(event)}{odds(event) + 1}
$$

$$
Pr(event) = \frac{exp(logit(event))}{1 + exp(logit(event))}
$$

Here, our *event* will be "movie passes the Bechdel-Wallace test" (`bechdel` = Pass)

## Model `mod_1`

```{r}
#| echo: true
mod_1 <- glm((bechdel == "Pass") ~ age,
             data = mov23a, family = binomial(link = "logit"))
mod_1
```

$$
\begin{aligned}
\log\left[ \frac { \widehat{P( \operatorname{bechdel = Pass})} }{ 1 - \widehat{P( \operatorname{bechdel = Pass})} } \right] &= 0.780 - 0.023(\operatorname{age})
\end{aligned}
$$

## Tidied `mod_1` coefficients

```{r}
#| echo: true
tidy(mod_1, conf.int = TRUE, conf.level = 0.90) |> 
  gt() |> fmt_number(decimals = 3) |> tab_options(table.font.size = 24)
```

Note that I haven't done any exponentiating here.

$$
\begin{aligned}
\log\left[ \frac { \widehat{P( \operatorname{bechdel = Pass} )} }{ 1 - \widehat{P( \operatorname{bechdel = Pass} )} } \right] &= 0.780 - 0.023(\operatorname{age})
\end{aligned}
$$

## `mod_1` predicts a movie with `age` = 50

$$
\begin{aligned}
\log\left[ \frac { \widehat{P( \operatorname{bechdel = Pass} )} }{ 1 - \widehat{P( \operatorname{bechdel = Pass} )} } \right] &= 0.780 - 0.023(\operatorname{age})
\end{aligned}
$$

$$
logit(bechdel = Pass) = 0.780 - .023 (50) = -0.37
$$

$$
odds(bechdel = Pass) = exp(-0.37) = 0.691
$$

$$
Pr(bechdel = Pass) = 0.691 / (1 + 0.691) = 0.41
$$

Estimated Probability of Passing Bechdel-Wallace Test: 41%.

## Three extra movies (not in `mov23a`)

```{r}
#| echo: true

new3_a <- tibble(age = c(50, 50, 20), 
               film = c("Godfather II", "Chinatown", "Incredibles"))

augment(mod_1, newdata = new3_a, type.predict = "response") |> 
  gt() |> tab_options(table.font.size = 24)
```

## Exponentiating `mod_1` Coefficients

```{r}
#| echo: true
tidy(mod_1, exponentiate = TRUE, conf.int = TRUE, conf.level = 0.90) |> 
  gt() |> fmt_number(decimals = 3) |> tab_options(table.font.size = 24)
```

The exponentiated slope coefficient (for age) is very useful. Suppose we compare two films. The older movie was made 1 year earlier than the newer movie. What does our `mod_1` say about the effect of the movie's `age`?

-   The exponentiated coefficient for `age`, 0.977, describes the **relative odds** of passing the Bechdel-Wallace test.

## Interpreting the Relative Odds

The movie whose `age` is one year older has 0.977 times the odds (97.7% of the odds) of the younger movie of passing the Bechdel-Wallace test, according to `mod_1`.

-   Movie A: age = 10, has log odds(pass) = 0.780 - 0.023 (10) = 0.55, so odds(pass) = exp(0.55) = 1.733
-   Movie B: age = 9, has log odds(pass) = 0.780 - 0.023 (9) = 0.573, so odds(pass) = exp(0.573) = 1.774
-   Relative odds (A vs. B) are thus 1.733 / 1.774 = 0.977

## Relative Odds with 2-year gap

Exponentiated `age` coefficient is 0.977, according to `mod_1`. What does this imply about the impact on the odds of passing when we have a 2-year difference in `age`?

-   Movie C: age = 12, has log odds(pass) = 0.780 - 0.023 (12) = 0.504, so odds(pass) = exp(0.504) = 1.655329
-   Movie A: age = 10, has log odds(pass) = 0.780 - 0.023 (10) = 0.55, so odds(pass) = exp(0.55) = 1.733253
-   Relative odds (C vs. A) are 1.655329 / 1.733253 = 0.955

Note that $0.977^{2} = 0.955$, as well.

## Relative Odds with 10-year gap

Exponentiated `age` coefficient is 0.977, according to `mod_1`. What does this imply about a 10-year difference in `age`?

-   Movie D: age = 20, has log odds(pass) = 0.780 - 0.023 (20) = 0.32, so odds(pass) = exp(0.32) = 1.377128
-   Movie A: age = 10, has log odds(pass) = 0.780 - 0.023 (10) = 0.55, so odds(pass) = exp(0.55) = 1.733253
-   Relative odds (D vs. A) are 1.377128 / 1.733253 = 0.79

Note that $0.977^{10} = 0.79$, as well.

## summary of `mod_1`

```{r}
#| echo: true

summary(mod_1)
```

## Likelihood Ratio Test: Model 1

-   compares model `mod_1` to a null model (with only an intercept term)

```{r}
#| echo: true
anova(mod_1, test = "LRT")
```

## Other ANOVA options for `glm()`

-   We can also get Rao's efficient score test (test = `"Rao"`) or Pearson's chi-square test (test = `"Chisq"`)

```{r}
#| echo: true
anova(mod_1, test = "Rao")
```

## What's in `glance(mod_1)`? {.smaller}

```{r}
#| echo: true

glance(mod_1) |>
  gt() |> tab_options(table.font.size = 24)
```

-   `nobs` = we fit null model and `mod_1` using 187 observations
-   null model (intercept) has 186 residual df (`df.null`) with `null.deviance` of 255.3
-   `mod_1` (includes age) has 185 residual df (`df.residual`) with `deviance` of 250.6
-   Think of deviance quantifying what has not yet been explained by model
    -   Our `mod_1` has deviance = -2*log likelihood (`logLik`)
    -   These are the elements of the ANOVA tests we discussed
-   `AIC` and `BIC` for comparing models for the same outcome, as in linear regression

## Evaluating prediction quality? {.smaller}

The Receiver Operating Characteristic (ROC) curve is one approach. We can calculate the Area under this curve (sometimes labeled AUC or just C). AUC falls between 0 and 1.

| AUC | Interpretation                                        |
|----:|:------------------------------------------------------|
| 0.5 | A coin-flip. Model is no better than flipping a coin. |
| 0.6 | Still a fairly weak model.                            |
| 0.7 | Low end of an "OK" model fit.                         |
| 0.8 | Pretty good predictive performance.                   |
| 0.9 | Outstanding predictive performance.                   |
| 1.0 | Perfect predictive performance.                       |

## How well does `mod_1` predict?

1.  Collected predicted probabilities for our `mov23a` data:

```{r}
#| echo: true
predict.prob1 <- predict(mod_1, type = "response")
```

2.  Calculate the ROC curve (`roc()` from `pROC` package)

```{r}
#| echo: true
roc1 <- roc(mod_1$data$bechdel, predict.prob1)
roc1
```

## Plotting the ROC Curve for `mod_1`

```{r}
#| echo: true

plot(roc1, main = "ROC Curve for Model mod_1", lwd = 2, col = "navy")
legend('bottomright', legend = paste("AUC: ", round_half_up(auc(roc1),3)))
```

## `mod_1` summaries after `lrm` fit {.smaller}

```{r}
#| echo: true

d <- datadist(mov23a); options(datadist = "d")
mod1_lrm <- lrm((bechdel == "Pass") ~ age, data = mov23a, 
                x = TRUE, y = TRUE)
mod1_lrm
```

-   Here, C = C statistic (AUC), Somers' d = Dxy.
-   Note that C = 0.5 + Dxy/2, by definition.

## Bootstrap validate `mod_1` summaries

```{r}
#| echo: true
set.seed(20240208); validate(mod1_lrm, B = 50)
```

Since C = 0.5 + Dxy / 2, our index-corrected (e.g., bootstrap-validated) C statistic = 0.5 + (0.1487/2) = 0.57435

## Effects Plot for `mod_1`

```{r}
#| echo: true

plot(summary(mod1_lrm))
```

## `mod_1` on Probability Scale

```{r}
#| echo: true

ggplot(Predict(mod1_lrm, fun = plogis))
```

# Predicting Pr(`bechdel` = Pass) using three predictors

## Model `mod_2`

```{r}
#| echo: true
mod_2 <- glm((bechdel == "Pass") ~ age + metascore + mpa3, data = mov23a, 
             family = binomial(link = logit))

mod_2
```

## Our `mod_2` Equation

$$
\begin{aligned}
\log\left[ \frac { \widehat{P( \operatorname{bechdel = Pass} )} }{ 1 - \widehat{P( \operatorname{bechdel = Pass} )} } \right] &= 1.453 - 0.028(\operatorname{age})\\
&\quad - 0.009(\operatorname{meta\_score})\\
&\quad - 0.163(\operatorname{mpa3}_{\operatorname{R}})\\
&\quad + 0.483(\operatorname{mpa3}_{\operatorname{Other}})
\end{aligned}
$$

## Tidied `mod_2` coefficients

```{r}
#| echo: true
tidy(mod_2, conf.int = TRUE, conf.level = 0.90) |> 
  gt() |> fmt_number(decimals = 3) |> tab_options(table.font.size = 24)
```

## Predictions for our three extra movies

```{r}
#| echo: true
new3_b <- tibble(
  film = c("Godfather II", "Chinatown", "Incredibles"),
  age = c(50, 50, 20), 
  metascore = c(90, 92, 90), 
  mpa3 = c("R", "R", "Other") )

augment(mod_2, newdata = new3_b, type.predict = "response") |> 
  gt() |> tab_options(table.font.size = 24)
```

## Tidied `mod_2` Odds Ratios

After exponentiating...

```{r}
#| echo: true
tidy(mod_2, exponentiate = TRUE, 
     conf.int = TRUE, conf.level = 0.90) |> 
  gt() |> fmt_number(decimals = 3) |> tab_options(table.font.size = 24)
```

## glance for `mod_1` and `mod_2`

```{r}
#| echo: true

bind_rows(glance(mod_1), glance(mod_2)) |>
  mutate(model = c("mod_1", "mod_2")) |>
  gt() |> 
  fmt_number(columns = logLik:BIC, decimals = 1) |>
  tab_options(table.font.size = 24)
```

-   What conclusions does this output suggest?

## Compare "Nested" Models

-   This is OK since `mod_1` is a subset of `mod_2`

```{r}
#| echo: true
anova(mod_1, mod_2, test = "LRT")
```

-   Rao's efficient score test (test = `"Rao"`) yields p = 0.2622
-   Pearson's $\chi^2$ test (test = `"Chisq"`) also yields p = 0.2544
-   Conclusions?

## Plotting the ROC curve for `mod_2`

```{r}
#| echo: true

predict.prob2 <- predict(mod_2, type = "response")
roc2 <- roc(mod_2$data$bechdel, predict.prob2)
plot(roc2, main = "ROC Curve for mod_2", lwd = 2, col = "navy")
legend('bottomright', legend = paste("AUC: ",round_half_up(auc(roc2),3)))
```

## `mod_2` via `lrm` fit

```{r}
#| echo: true

d <- datadist(mov23a); options(datadist = "d")
mod2_lrm <- lrm((bechdel == "Pass") ~ age + metascore + mpa3, 
                data = mov23a, x = TRUE, y = TRUE)

mod2_lrm
```

## Effects Plot for `mod_2`

```{r}
#| echo: true

plot(summary(mod2_lrm))
```

## `mod_2` on Probability Scale

```{r}
#| echo: true

ggplot(Predict(mod2_lrm, fun = plogis))
```

## Bootstrap validate `mod_2` summaries

```{r}
#| echo: true
set.seed(202402082); validate(mod2_lrm, B = 75)
```

Since C = 0.5 + Dxy / 2, our index-corrected (e.g., bootstrap-validated) C statistic = 0.5 + (0.1605/2) = 0.58025

-   For `mod_1`, our validated C was 0.57435 and $R^2$ was 0.0150

# Predicting Pr(`bechdel` = Pass) using five predictors (leaving out `mpa3`)

## Model `mod_3`

```{r}
#| echo: true
mod_3 <- glm((bechdel == "Pass") ~ age + metascore + 
               gross + comedy + drama,
             data = mov23a, family = binomial(link = logit))

mod_3
```

## `mod_3` Prediction Equation

$$
\begin{aligned}
logit( P( \operatorname{bechdel = Pass} ) ) &= 0.865 - 0.016(\operatorname{age})\\
&\quad - 0.011(\operatorname{meta\_score})\\
&\quad + 0.0009(\operatorname{gross})\\
&\quad + 0.361(\operatorname{comedy})\\
&\quad + 0.297(\operatorname{drama})
\end{aligned}
$$

## Tidied `mod_3` odds ratios

Coefficients have been exponentiated here...

```{r}
#| echo: true
tidy(mod_3, exponentiate = TRUE, conf.int = TRUE, conf.level = 0.90) |> 
  gt() |> fmt_number(decimals = 3) |> tab_options(table.font.size = 24)
```

## Compare models with `glance()`

```{r}
#| echo: true

bind_rows(glance(mod_1), glance(mod_2), glance(mod_3)) |>
  mutate(model = c("mod_1", "mod_2", "mod_3")) |>
  gt() |> 
  fmt_number(columns = logLik:BIC, decimals = 1) |>
  tab_options(table.font.size = 24)
```

## ANOVA comparison of `mod_1` to `mod_3`

```{r}
#| echo: true
anova(mod_1, mod_3, test = "LRT")
```

- Rao test: p = 0.2239
- Note that `mod_1` is nested in `mod_3` but `mod_2` isn't.

## ROC curve for `mod_3`

```{r}
#| echo: true
predict.prob3 <- predict(mod_3, type = "response")
roc3 <- roc(mod_3$data$bechdel, predict.prob3)
plot(roc3, main = "ROC Curve for Model mod_3", lwd = 2, col = "red")
legend('bottomright', legend = paste("AUC: ",round_half_up(auc(roc3),3)))
```

## Fit `mod_3` via `lrm()`

```{r}
#| echo: true

d <- datadist(mov23a); options(datadist = "d")

mod3_lrm <- lrm((bechdel == "Pass") ~ age + 
                  metascore + gross + comedy + drama,
                data = mov23a, x = TRUE, y = TRUE)
```

## `mod_3` via `lrm()` summaries

```{r}
#| echo: true

mod3_lrm
```

## Effects Plot for `mod_3`

```{r}
#| echo: true
plot(summary(mod3_lrm))
```

## `mod_3` on Probability Scale

```{r}
#| echo: true

ggplot(Predict(mod3_lrm, fun = plogis))
```

## Bootstrap validate `mod_3` summaries

```{r}
#| echo: true
set.seed(202402083); validate(mod3_lrm, B = 60)
```

Bootstrap-validated C statistic = 0.5 + (0.1689/2) = 0.58445

-   For `mod_1`, our validated C was 0.57435 and $R^2$ was 0.0150
-   For `mod_2`, our validated C = 0.58025, with $R^2$ = 0.0165

## Our Three Extra Movies

```{r}
#| echo: true
new3_c <- tibble(
  film = c("Godfather II", "Chinatown", "Incredibles"),
  age = c(50, 50, 20), metascore = c(90, 92, 90), 
  comedy = c(0, 0, 0), drama = c(1, 1, 0), 
  gross = c(288.741, 175.946, 992.372) )

augment(mod_3, newdata = new3_c, type.predict = "response") |>
  gt() |> tab_options(table.font.size = 24)
```

## Actual Bechdel-Wallace Test Results {.smaller}

|                   Film | Bechdel-Wallace Rating | Bechdel Test |
|-----------------------:|:----------------------:|:------------:|
| The Godfather, Part II |           2            |     Fail     |
|              Chinatown |           2            |     Fail     |
|        The Incredibles |           3            |     Pass     |

Ratings obtained through API at bechdeltest.com

-   0 means "no two named women"
-   1 means "no talking between the women"
-   2 means "talking only about a man"
-   3 means "passes the test"

Example: <https://bechdeltest.com/api/v1/getMovieByImdbId?imdbid=0071315>

## Nomogram for `mod_3`

```{r}
#| echo: true

plot(nomogram(mod3_lrm, fun = plogis, funlabel = "Pr(PASS)"),
     lplabel = "log odds (PASS)")
```

## Next Week (back in person!)

1. Walking through necessary analyses for Project A's logistic regression model
2. Bringing non-linear terms into our logistic regression models
3. Dealing with missing data more carefully

### Project A Plan due MONDAY 2024-02-12 

Get everything into Canvas by Noon Monday, **please**!
